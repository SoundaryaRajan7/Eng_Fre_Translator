{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!nvidia-smi","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-19T19:53:29.056229Z","iopub.execute_input":"2025-02-19T19:53:29.056558Z","iopub.status.idle":"2025-02-19T19:53:30.176326Z","shell.execute_reply.started":"2025-02-19T19:53:29.056518Z","shell.execute_reply":"2025-02-19T19:53:30.175229Z"}},"outputs":[{"name":"stdout","text":"Wed Feb 19 19:53:29 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n| N/A   37C    P8              9W /   70W |       1MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   1  Tesla T4                       Off |   00000000:00:05.0 Off |                    0 |\n| N/A   38C    P8             10W /   70W |       1MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|  No running processes found                                                             |\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install datasets transformers[sentencepiece] sacrebleu -q","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T19:53:30.178156Z","iopub.execute_input":"2025-02-19T19:53:30.178460Z","iopub.status.idle":"2025-02-19T19:53:39.998639Z","shell.execute_reply.started":"2025-02-19T19:53:30.178433Z","shell.execute_reply":"2025-02-19T19:53:39.997444Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import os\nimport sys\nimport transformers\nimport tensorflow as tf\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer\nfrom transformers import TFAutoModelForSeq2SeqLM, DataCollatorForSeq2Seq\nfrom transformers import AdamWeightDecay\nfrom transformers import AutoTokenizer, TFAutoModelForSeq2SeqLM","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T19:53:40.000059Z","iopub.execute_input":"2025-02-19T19:53:40.000361Z","iopub.status.idle":"2025-02-19T19:53:57.591289Z","shell.execute_reply.started":"2025-02-19T19:53:40.000335Z","shell.execute_reply":"2025-02-19T19:53:57.590619Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"**Model from Hugging Face** \r\n\"https://huggingface.co/Helsinki-NLP/opus-mt-en-fr\"","metadata":{}},{"cell_type":"code","source":"model_checkpoint = \"Helsinki-NLP/opus-mt-en-fr\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T19:53:57.592863Z","iopub.execute_input":"2025-02-19T19:53:57.593373Z","iopub.status.idle":"2025-02-19T19:53:57.597138Z","shell.execute_reply.started":"2025-02-19T19:53:57.593346Z","shell.execute_reply":"2025-02-19T19:53:57.596334Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"**Dataset from Hugging Face**\r\nhttps://huggingface.co/datasets/arielogg/anki_globalvoices_en_fr","metadata":{}},{"cell_type":"code","source":"raw_datasets = load_dataset(\"arielogg/anki_globalvoices_en_fr\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T19:53:57.598132Z","iopub.execute_input":"2025-02-19T19:53:57.598504Z","iopub.status.idle":"2025-02-19T19:54:04.112343Z","shell.execute_reply.started":"2025-02-19T19:53:57.598456Z","shell.execute_reply":"2025-02-19T19:54:04.111426Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/3.33k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6d9d1a1b32c4137a75bebf3bb239c96"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train.csv:   0%|          | 0.00/74.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d349e3934a914dc6a843395d27443e1f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"validation.csv:   0%|          | 0.00/9.28M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f8b3d17dbdd748918686a532580a0010"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test.csv:   0%|          | 0.00/9.33M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"99636ac27687494bac48917ecf8d55d9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/439064 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"989c09ce0c364b6a9b9dd861abc61a95"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/54883 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"298a6c14c4a844d68dabbfb649c4233b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/54884 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"96e9f818cc624d2baafbaf5492779111"}},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"raw_datasets\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T19:54:04.113396Z","iopub.execute_input":"2025-02-19T19:54:04.113695Z","iopub.status.idle":"2025-02-19T19:54:04.119333Z","shell.execute_reply.started":"2025-02-19T19:54:04.113668Z","shell.execute_reply":"2025-02-19T19:54:04.118484Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['source', 'target'],\n        num_rows: 439064\n    })\n    validation: Dataset({\n        features: ['source', 'target'],\n        num_rows: 54883\n    })\n    test: Dataset({\n        features: ['source', 'target'],\n        num_rows: 54884\n    })\n})"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"raw_datasets['train'][2]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T19:54:04.120440Z","iopub.execute_input":"2025-02-19T19:54:04.120762Z","iopub.status.idle":"2025-02-19T19:54:04.132407Z","shell.execute_reply.started":"2025-02-19T19:54:04.120716Z","shell.execute_reply":"2025-02-19T19:54:04.131641Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"{'source': \"tom's flight will be arriving early.\",\n 'target': 'le vol de tom va atterrir plus tôt que prévu.'}"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T19:54:04.133526Z","iopub.execute_input":"2025-02-19T19:54:04.133871Z","iopub.status.idle":"2025-02-19T19:54:05.066699Z","shell.execute_reply.started":"2025-02-19T19:54:04.133836Z","shell.execute_reply":"2025-02-19T19:54:05.065796Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/42.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"544f51fddd2441a98e4a461be06f088d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.42k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fafd641076d0486abe8b2c227538b705"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"source.spm:   0%|          | 0.00/778k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef5920d019aa4722b19ad8b065431ceb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"target.spm:   0%|          | 0.00/802k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e6352aebc98843f983a2974a2239e4d4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.34M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a25b60826ac646cf99a7fc39bbdee6a2"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n  warnings.warn(\"Recommended: pip install sacremoses.\")\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"tokenizer([\"Hello, this is a sentence!\", \"This is another sentence.\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T19:54:05.068073Z","iopub.execute_input":"2025-02-19T19:54:05.068447Z","iopub.status.idle":"2025-02-19T19:54:05.075312Z","shell.execute_reply.started":"2025-02-19T19:54:05.068408Z","shell.execute_reply":"2025-02-19T19:54:05.074217Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"{'input_ids': [[10537, 2, 67, 32, 15, 5776, 145, 0], [160, 32, 1036, 5776, 3, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1]]}"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"with tokenizer.as_target_tokenizer():\n    print(tokenizer([\"le vol de tom va atterrir plus tôt que prévu.\"]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T19:54:05.078728Z","iopub.execute_input":"2025-02-19T19:54:05.079063Z","iopub.status.idle":"2025-02-19T19:54:05.089005Z","shell.execute_reply.started":"2025-02-19T19:54:05.079038Z","shell.execute_reply":"2025-02-19T19:54:05.088107Z"}},"outputs":[{"name":"stdout","text":"{'input_ids': [[19, 2730, 5, 49, 10045, 740, 33158, 139, 65, 5741, 29, 2493, 3, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:4114: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"print(raw_datasets[\"train\"].column_names)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T19:54:05.090093Z","iopub.execute_input":"2025-02-19T19:54:05.090364Z","iopub.status.idle":"2025-02-19T19:54:05.095115Z","shell.execute_reply.started":"2025-02-19T19:54:05.090339Z","shell.execute_reply":"2025-02-19T19:54:05.094249Z"}},"outputs":[{"name":"stdout","text":"['source', 'target']\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"max_input_length = 128\nmax_target_length = 128\n\nsource_lang = \"en\"\ntarget_lang = \"fr\"\n\ndef preprocess_function(examples):\n    # Access the source and target fields directly\n    inputs = examples[\"source\"]  # Input sentences\n    targets = examples[\"target\"]  # Target sentences\n\n    # Tokenize the inputs\n    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n\n    # Tokenize the targets\n    with tokenizer.as_target_tokenizer():\n        labels = tokenizer(targets, max_length=max_target_length, truncation=True)\n\n    # Add tokenized labels to the inputs\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T19:54:05.096246Z","iopub.execute_input":"2025-02-19T19:54:05.096563Z","iopub.status.idle":"2025-02-19T19:54:05.103985Z","shell.execute_reply.started":"2025-02-19T19:54:05.096528Z","shell.execute_reply":"2025-02-19T19:54:05.103246Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"preprocess_function(raw_datasets[\"train\"][:5])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T19:54:05.104836Z","iopub.execute_input":"2025-02-19T19:54:05.105051Z","iopub.status.idle":"2025-02-19T19:54:05.117884Z","shell.execute_reply.started":"2025-02-19T19:54:05.105022Z","shell.execute_reply":"2025-02-19T19:54:05.117096Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"{'input_ids': [[1394, 2, 147, 232, 224, 4315, 273, 24, 13485, 64, 98, 30667, 7, 4, 16952, 28, 79, 2737, 30, 27486, 33, 154, 86, 17808, 10, 1787, 15, 6877, 7, 11610, 1162, 57, 6397, 11610, 1162, 3, 0], [12249, 37, 15, 191, 3482, 94, 9543, 18, 4, 3086, 2090, 7639, 1071, 670, 75, 62, 10790, 37, 4, 25084, 7, 49, 1, 226, 20107, 108, 720, 30135, 1, 3, 0], [12, 122, 6, 9, 6135, 86, 45, 23138, 1834, 3, 0], [18, 4, 703, 2, 599, 2308, 26, 192, 1594, 48, 235, 599, 69, 12393, 7, 270, 599, 69, 1905, 3, 0], [22268, 36702, 15, 11230, 7417, 11804, 37, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1]], 'labels': [[1416, 6, 1051, 2, 65, 5, 4847, 1127, 296, 24, 2651, 1234, 13293, 22, 507, 28, 91, 2134, 36, 27486, 68, 6, 489, 3446, 8038, 11, 6100, 816, 125, 11610, 1162, 59, 68, 6, 489, 23, 6159, 816, 3, 0], [1768, 5908, 37, 76, 1146, 49, 15839, 5053, 9, 4296, 111, 18, 4, 3086, 15242, 1162, 1071, 10005, 146, 2496, 37, 4, 317, 15125, 7, 49, 1, 226, 93, 7282, 5049, 12634, 1, 3, 0], [19, 2730, 5, 49, 10045, 740, 33158, 139, 65, 5741, 29, 2493, 3, 0], [23, 611, 5, 356, 2, 286, 116, 15, 1720, 371, 1324, 2, 127, 174, 286, 295, 12393, 51, 5, 66, 68, 6, 431, 6556, 3, 0], [62, 6865, 883, 15, 11230, 7417, 6238, 278, 162, 2798, 328, 37, 0]]}"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"tokenized_datasets = raw_datasets.map(preprocess_function, batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T19:54:05.118901Z","iopub.execute_input":"2025-02-19T19:54:05.119411Z","iopub.status.idle":"2025-02-19T19:55:40.882297Z","shell.execute_reply.started":"2025-02-19T19:54:05.119386Z","shell.execute_reply":"2025-02-19T19:55:40.881319Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/439064 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad3af8ff35da44278a0360638c06ae73"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/54883 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6f4d69a676445279224b82d966c2bc1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/54884 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f7e6bb77b3c40478aec686e46bccf50"}},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"model = TFAutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T19:55:40.883680Z","iopub.execute_input":"2025-02-19T19:55:40.884049Z","iopub.status.idle":"2025-02-19T19:55:48.357496Z","shell.execute_reply.started":"2025-02-19T19:55:40.884001Z","shell.execute_reply":"2025-02-19T19:55:48.356702Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tf_model.h5:   0%|          | 0.00/301M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c8c3f396cff3463a8c837cf7890a35b6"}},"metadata":{}},{"name":"stderr","text":"All model checkpoint layers were used when initializing TFMarianMTModel.\n\nAll the layers of TFMarianMTModel were initialized from the model checkpoint at Helsinki-NLP/opus-mt-en-fr.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFMarianMTModel for predictions without further training.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c4058f6b7a464d9ab98d6cd147dd6257"}},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"batch_size = 32\nlearning_rate = 3e-5\nweight_decay = 0.01\nnum_train_epochs = 3","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T19:55:48.358491Z","iopub.execute_input":"2025-02-19T19:55:48.358757Z","iopub.status.idle":"2025-02-19T19:55:48.362806Z","shell.execute_reply.started":"2025-02-19T19:55:48.358732Z","shell.execute_reply":"2025-02-19T19:55:48.361852Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors=\"tf\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T19:55:48.363810Z","iopub.execute_input":"2025-02-19T19:55:48.364057Z","iopub.status.idle":"2025-02-19T19:55:48.372410Z","shell.execute_reply.started":"2025-02-19T19:55:48.364018Z","shell.execute_reply":"2025-02-19T19:55:48.371603Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"generation_data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors=\"tf\", pad_to_multiple_of=128)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T19:55:48.373302Z","iopub.execute_input":"2025-02-19T19:55:48.373537Z","iopub.status.idle":"2025-02-19T19:55:48.381761Z","shell.execute_reply.started":"2025-02-19T19:55:48.373514Z","shell.execute_reply":"2025-02-19T19:55:48.381068Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"train_dataset = model.prepare_tf_dataset(\n    tokenized_datasets[\"train\"],\n    batch_size=batch_size,\n    shuffle=True,\n    collate_fn=data_collator,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T19:55:48.382732Z","iopub.execute_input":"2025-02-19T19:55:48.382979Z","iopub.status.idle":"2025-02-19T19:55:49.515349Z","shell.execute_reply.started":"2025-02-19T19:55:48.382955Z","shell.execute_reply":"2025-02-19T19:55:49.514705Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"validation_dataset = model.prepare_tf_dataset(\n    tokenized_datasets[\"validation\"],\n    batch_size=batch_size,\n    shuffle=False,\n    collate_fn=data_collator,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T19:55:49.516372Z","iopub.execute_input":"2025-02-19T19:55:49.516664Z","iopub.status.idle":"2025-02-19T19:55:49.667008Z","shell.execute_reply.started":"2025-02-19T19:55:49.516638Z","shell.execute_reply":"2025-02-19T19:55:49.666315Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"generation_dataset = model.prepare_tf_dataset(\n    tokenized_datasets[\"validation\"],\n    batch_size=8,\n    shuffle=False,\n    collate_fn=generation_data_collator,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T19:55:49.667973Z","iopub.execute_input":"2025-02-19T19:55:49.668240Z","iopub.status.idle":"2025-02-19T19:55:49.817284Z","shell.execute_reply.started":"2025-02-19T19:55:49.668215Z","shell.execute_reply":"2025-02-19T19:55:49.816363Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"optimizer = AdamWeightDecay(learning_rate=learning_rate, weight_decay_rate=weight_decay)\nmodel.compile(optimizer=optimizer)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T19:55:49.818371Z","iopub.execute_input":"2025-02-19T19:55:49.818670Z","iopub.status.idle":"2025-02-19T19:55:49.833270Z","shell.execute_reply.started":"2025-02-19T19:55:49.818643Z","shell.execute_reply":"2025-02-19T19:55:49.832628Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"model.fit(train_dataset, validation_data=validation_dataset, epochs=5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T19:55:49.834190Z","iopub.execute_input":"2025-02-19T19:55:49.834511Z","iopub.status.idle":"2025-02-20T06:17:40.200780Z","shell.execute_reply.started":"2025-02-19T19:55:49.834470Z","shell.execute_reply":"2025-02-20T06:17:40.199940Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/5\nWARNING: AutoGraph could not transform <function infer_framework at 0x7d031e467f40> and will run it as-is.\nCause: for/else statement not yet supported\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n13720/13720 [==============================] - 7522s 543ms/step - loss: 1.1193 - val_loss: 1.0146\nEpoch 2/5\n13720/13720 [==============================] - 7430s 542ms/step - loss: 1.0019 - val_loss: 1.0027\nEpoch 3/5\n13720/13720 [==============================] - 7462s 544ms/step - loss: 0.9374 - val_loss: 1.0013\nEpoch 4/5\n13720/13720 [==============================] - 7447s 543ms/step - loss: 0.8882 - val_loss: 1.0006\nEpoch 5/5\n13720/13720 [==============================] - 7449s 543ms/step - loss: 0.8463 - val_loss: 1.0078\n","output_type":"stream"},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"<tf_keras.src.callbacks.History at 0x7d024c54a410>"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"# Evaluate the model on the validation dataset\nevaluation_results = model.evaluate(validation_dataset)\n\n# Print Validation Loss & Accuracy\nprint(f\"Validation Loss: {evaluation_results:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T06:17:40.201909Z","iopub.execute_input":"2025-02-20T06:17:40.202188Z","iopub.status.idle":"2025-02-20T06:23:54.990270Z","shell.execute_reply.started":"2025-02-20T06:17:40.202162Z","shell.execute_reply":"2025-02-20T06:23:54.989429Z"}},"outputs":[{"name":"stdout","text":"1716/1716 [==============================] - 375s 218ms/step - loss: 1.0078\nValidation Loss: 1.0078\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"import sacrebleu\nfrom transformers import pipeline\n\n# Load trained translation model\ntranslator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-en-fr\")\n\n# Sample test sentences\ntest_sentences = [\n    \"Hello, how are you?\",\n    \"Artificial intelligence is transforming industries.\",\n    \"Where can I find the nearest coffee shop?\",\n    \"Machine learning is a subset of AI.\"\n]\n\n# Human reference translations (Ground truth)\ntrue_translations = [\n    \"Bonjour, comment ça va ?\",\n    \"L'intelligence artificielle transforme les industries.\",\n    \"Où puis-je trouver le café le plus proche ?\",\n    \"L'apprentissage automatique est un sous-ensemble de l'IA.\"\n]\n\n# Generate translations from model\npredicted_translations = [translator(sentence)[0]['translation_text'] for sentence in test_sentences]\n\n# Compute BLEU Score\nbleu_score = sacrebleu.corpus_bleu(predicted_translations, [true_translations])\nprint(f\"BLEU Score: {bleu_score.score:.2f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T06:23:54.991274Z","iopub.execute_input":"2025-02-20T06:23:54.991518Z","iopub.status.idle":"2025-02-20T06:24:01.911282Z","shell.execute_reply.started":"2025-02-20T06:23:54.991494Z","shell.execute_reply":"2025-02-20T06:24:01.910242Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/301M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6551d6315cc407ab929237dfbd66b28"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n  warnings.warn(\"Recommended: pip install sacremoses.\")\nHardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n","output_type":"stream"},{"name":"stdout","text":"BLEU Score: 88.14\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"model.save_pretrained(\"model\")\ntokenizer.save_pretrained(\"model\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T06:32:20.295168Z","iopub.execute_input":"2025-02-20T06:32:20.295951Z","iopub.status.idle":"2025-02-20T06:32:21.406938Z","shell.execute_reply.started":"2025-02-20T06:32:20.295916Z","shell.execute_reply":"2025-02-20T06:32:21.405996Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/configuration_utils.py:388: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[59513]]}\n  warnings.warn(\n","output_type":"stream"},{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"('model/tokenizer_config.json',\n 'model/special_tokens_map.json',\n 'model/vocab.json',\n 'model/source.spm',\n 'model/target.spm',\n 'model/added_tokens.json')"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"!zip -r model.zip model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T06:32:53.699057Z","iopub.execute_input":"2025-02-20T06:32:53.699775Z","iopub.status.idle":"2025-02-20T06:33:10.266349Z","shell.execute_reply.started":"2025-02-20T06:32:53.699744Z","shell.execute_reply":"2025-02-20T06:33:10.265081Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"  adding: model/ (stored 0%)\n  adding: model/special_tokens_map.json (deflated 35%)\n  adding: model/generation_config.json (deflated 43%)\n  adding: model/config.json (deflated 61%)\n  adding: model/source.spm (deflated 49%)\n  adding: model/tf_model.h5 (deflated 7%)\n  adding: model/tokenizer_config.json (deflated 68%)\n  adding: model/target.spm (deflated 50%)\n  adding: model/vocab.json (deflated 70%)\n","output_type":"stream"}],"execution_count":27}]}